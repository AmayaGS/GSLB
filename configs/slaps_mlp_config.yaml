Default:
  epochs: 200
  epochs_adj: 2000
  lr: 0.001
  lr_adj: 0.01
  w_decay: 0.0005
  w_decay_adj: 0.0
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.25
  dataset: cora
  nlayers: 2
  nlayers_adj: 2
  patience: 10
  k: 20
  ratio: 20
  epoch_d: 5
  lambda_: 0.1
  nr: 5
  knn_metric: cosine
  model: end2end
  i: 6
  non_linearity: elu
  mlp_act: relu
  normalization: sym
  mlp_h: 50
  gen_mode: 0
  sparse: 0
  noise: mask
  loss: mse

cora:
  dataset: cora
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1433
  mlp_act: relu
  epoch_d: 5

citeseer:
  dataset: citeseer
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 1024
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 30
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_act: relu
  mlp_h: 3703
  epoch_d: 5

pubmed:
  dataset: pubmed
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.01
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 128
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.5
  dropout_adj2: 0.5
  k: 15
  lambda_: 10.0
  nr: 5
  ratio: 20
  model: end2end
  gen_mode: 1
  non_linearity: relu
  mlp_h: 500
  mlp_act: relu
  epoch_d: 5
  sparse: 1

ogbn-arxiv:
  dataset: ogbn-arxiv
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0
  nlayers: 2
  nlayers_adj: 2
  hidden: 256
  hidden_adj: 256
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 15
  lambda_: 10.0
  nr: 5
  ratio: 100
  model: end2end
  gen_mode: 1
  non_linearity: relu
  mlp_h: 128
  mlp_act: relu
  epoch_d: 2001
  sparse: 1
  loss: mse
  noise: mask

cornell:
  dataset: cornell
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1703
  mlp_act: relu
  epoch_d: 5

actor:
  dataset: actor
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 932
  mlp_act: relu
  epoch_d: 5

texas:
  dataset: texas
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1703
  mlp_act: relu
  epoch_d: 5

wisconsin:
  dataset: wisconsin
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1703
  mlp_act: relu
  epoch_d: 5

chameleon:
  dataset: chameleon
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1433
  mlp_act: relu
  epoch_d: 5

squirrel:
  dataset: squirrel
  epochs_adj: 2000
  lr: 0.01
  lr_adj: 0.001
  w_decay: 0.0005
  nlayers: 2
  nlayers_adj: 2
  hidden: 32
  hidden_adj: 512
  dropout1: 0.5
  dropout2: 0.5
  dropout_adj1: 0.25
  dropout_adj2: 0.5
  k: 20
  lambda_: 10.0
  nr: 5
  ratio: 10
  model: end2end
  sparse: 0
  gen_mode: 1
  non_linearity: relu
  mlp_h: 1433
  mlp_act: relu
  epoch_d: 5